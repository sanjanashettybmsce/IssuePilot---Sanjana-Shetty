# IssueSense AI - Quick Reference Card

## ğŸš€ Start Here

```bash
# 1. Setup
cd /Users/sanjana/Desktop/IssuePilot
python3 -m venv venv && source venv/bin/activate
pip install -r requirements.txt
cp .env.example .env
# Edit .env with your GitHub token and OpenAI API key

# 2. Run Backend (Terminal 1)
python -m uvicorn backend.main:app --reload

# 3. Run Frontend (Terminal 2)
streamlit run frontend/app.py

# 4. Access
# Frontend: http://localhost:8501
# Backend API Docs: http://localhost:8000/docs
# Health Check: curl http://localhost:8000/health
```

## ğŸ“‹ API Endpoints

| Method | Path | Purpose |
|--------|------|---------|
| POST | `/analyze` | Analyze single issue |
| POST | `/batch-analyze` | Analyze multiple issues |
| GET | `/health` | Health check |
| GET | `/` | API info |
| GET | `/docs` | Swagger UI |

## ğŸ’» API Call Examples

### Analyze Issue
```bash
curl -X POST http://localhost:8000/analyze \
  -H "Content-Type: application/json" \
  -d '{"repo_url":"torvalds/linux","issue_number":12345}'
```

### Python
```python
import requests
response = requests.post("http://localhost:8000/analyze", json={
    "repo_url": "pallets/flask",
    "issue_number": 4789
})
print(response.json())
```

## ğŸ“ Project Structure

```
IssuePilot/
â”œâ”€â”€ backend/          # FastAPI server
â”‚   â”œâ”€â”€ main.py       # API endpoints
â”‚   â”œâ”€â”€ config.py     # Configuration
â”‚   â”œâ”€â”€ github_client.py    # GitHub API wrapper
â”‚   â”œâ”€â”€ context_enricher.py # Context gathering
â”‚   â”œâ”€â”€ llm_analyzer.py     # OpenAI integration
â”‚   â””â”€â”€ models.py     # Data models
â”œâ”€â”€ frontend/         # Streamlit UI
â”‚   â”œâ”€â”€ app.py        # Main UI
â”‚   â””â”€â”€ styles.py     # Styling
â”œâ”€â”€ requirements.txt  # Dependencies
â”œâ”€â”€ .env.example     # Config template
â”œâ”€â”€ README.md        # Overview
â”œâ”€â”€ SETUP.md         # Installation
â”œâ”€â”€ ARCHITECTURE.md  # Design details
â””â”€â”€ EXAMPLES.md      # Code examples
```

## âš™ï¸ Environment Variables

```bash
# Required
GITHUB_TOKEN=ghp_xxx...          # GitHub personal access token
OPENAI_API_KEY=sk-xxx...         # OpenAI API key

# Optional (defaults shown)
GITHUB_API_BASE_URL=https://api.github.com
OPENAI_MODEL=gpt-4-turbo-preview
BACKEND_HOST=localhost
BACKEND_PORT=8000
```

## ğŸ” What It Does

```
GitHub Issue + Comments
    â†“
GitHub API: Fetch details, linked items, files, commits
    â†“
Text Processing: Extract stack traces, error messages
    â†“
Context Enrichment: Compile comprehensive context
    â†“
OpenAI API: Analyze with LLM
    â†“
Response Validation: Ensure correct format
    â†“
Return: Structured JSON analysis
    {
      "summary": "Issue description",
      "type": "bug|feature|documentation|question|other",
      "priority_score": {"score": 1-5, "justification": "..."},
      "suggested_labels": ["label1", "label2", "label3"],
      "potential_impact": "Impact description"
    }
```

## ğŸ¨ UI Features

- **Input Section**: Repository URL + Issue number
- **Status Indicator**: Backend connection status
- **Results Display**: 
  - Summary
  - Issue type with emoji
  - Priority score with justification
  - Potential impact warning
  - Suggested labels
  - Raw JSON export
- **Sidebar**: Configuration, links, info

## ğŸ“Š Response Format

```json
{
  "summary": "Single sentence problem description",
  "type": "bug",
  "priority_score": {
    "score": 4,
    "justification": "Affects many users, blocking feature"
  },
  "suggested_labels": ["bug", "authentication", "critical"],
  "potential_impact": "Users cannot log in, blocking all access"
}
```

## ğŸ”§ Troubleshooting

| Problem | Solution |
|---------|----------|
| Cannot connect to backend | Start backend: `python -m uvicorn backend.main:app --reload` |
| GitHub token not set | Create `.env` file with `GITHUB_TOKEN=your_token` |
| OpenAI key not set | Add `OPENAI_API_KEY=your_key` to `.env` |
| Import errors | Run `pip install -r requirements.txt` |
| Repository not found | Check format is `owner/repo` |

## ğŸ“š Documentation

| File | Purpose |
|------|---------|
| README.md | Quick overview |
| SETUP.md | Detailed installation |
| ARCHITECTURE.md | System design |
| EXAMPLES.md | API usage examples |
| PROJECT_SUMMARY.md | Complete summary |

## ğŸŒ Testing Repositories

- `torvalds/linux` - Linux kernel
- `pallets/flask` - Web framework
- `django/django` - Django framework
- `nodejs/node` - Node.js runtime
- `rust-lang/rust` - Rust language

## â±ï¸ Performance

- GitHub context: 10-20s
- LLM analysis: 15-30s
- **Total**: ~30-60s per issue

## ğŸ”’ Security

- API keys in `.env` only (never commit)
- GitHub token scoped to minimal permissions
- Input validation on all endpoints
- No sensitive data in logs

## ğŸ’¡ Tips

1. Start with well-known repos (torvalds/linux, pallets/flask)
2. Test with recent issues (more context available)
3. Check backend logs for debugging
4. Use health endpoint to verify connection
5. Review raw JSON for integration needs

## ğŸš€ Next Steps

1. âœ… Install dependencies
2. âœ… Configure `.env`
3. âœ… Start backend & frontend
4. âœ… Analyze first issue
5. âœ… Explore UI and API
6. âœ… Integrate into workflows
7. âœ… Deploy to production

## ğŸ“ Quick Help

```bash
# Check health
curl http://localhost:8000/health

# View API docs
open http://localhost:8000/docs

# View frontend
open http://localhost:8501

# Check Python version
python3 --version

# List installed packages
pip list | grep -E "(fastapi|streamlit|openai)"
```

---

**Everything is ready to go!** ğŸ‰

See SETUP.md for detailed instructions.
